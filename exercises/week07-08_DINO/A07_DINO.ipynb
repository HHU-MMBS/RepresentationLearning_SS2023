{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HHU Deep Learning, SS2022/23, 26.05.2023, Prof. Dr. Markus Kollmann\n",
    "\n",
    "Lecturers and Tutoring is done by Tim Kaiser, Nikolas Adaloglou and Felix Michels.\n",
    "\n",
    "# Assignment 08 - DINO\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. The model\n",
    "2. The Loss Function\n",
    "3. The Dataset and Augmentations\n",
    "4. Training\n",
    "5. Evaluation\n",
    "6. Investigate the pseudo-label distribution\n",
    "\n",
    "---\n",
    "\n",
    "# Introduction\n",
    "\n",
    "DINO (self-**di**stillation with **no** labels) is a self-supervised learning method in which the output of a student model is trained to match the soft pseudo-labels produced by a teacher network.\n",
    "The teacher network is an exponential moving average (EMA) of the student network.\n",
    "For more information see the [original paper](https://arxiv.org/abs/2104.14294).\n",
    "\n",
    "In this exercise you will implement and train a DINO model on a medical dataset, the PathMNIST dataset from [medmnist](https://medmnist.com/) consisting of low resolution images of various colon pathologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Callable, Union, Optional\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a very small Vision Transformer (ViT) for relatively fast training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we work on small images (28x28) we need a small patch size\n",
    "vit_tiny_args = dict(patch_size=4, embed_dim=192, depth=12, num_heads=3, img_size=28, in_chans=3, num_classes=0,  pre_norm=True)\n",
    "def vit_tiny():\n",
    "    return VisionTransformer(**vit_tiny_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Less than 6 million parameters\n",
    "sum(p.numel() for p in vit_tiny().parameters() if p.requires_grad) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the DINO head\n",
    "Like SimCLR, DINO uses a MLP head to project the output of the ViT to a output space.\n",
    "Unlike SimCLR, the output dimension of the MLP can be much larger than the input dimension and is interpreted as pseudo label assignments.\n",
    "\n",
    "The DINO head has some peculiarities:\n",
    "- The first layers of the head is a `nlayers` MLP with GELU activations (but no activation on the last layer), with input dimension `in_dim`, hidden dimensions `hidden_dim` and output dimension `bottleneck_dim`.\n",
    "Since the output dimension of the DINO head is often quite large (e.g. 65K for ImageNet), the bottleneck dimension reduces the number of parameters in the last layer and allows a deeper MLP.\n",
    "- After this, the output is projected to the unit sphere (i.e. the output is normalized to unit length)\n",
    "- The last layer is a fully connected layer from `bottleneck_dim` to `out_dim`. This layer is weight normalized ([https://arxiv.org/abs/1602.07868](https://arxiv.org/abs/1602.07868)) which means that the direction and lengths of the columns of the weight matrix are decoupled and stored in different paramters. This can improve stability and speed of training. The weight normalization is implemented in `nn.utils.weight_norm`.\n",
    "Make sure that the length of these vectors (`weight_g`) are initialized to 1 and not trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINOHead(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, nlayers=3, hidden_dim=512, bottleneck_dim=128):\n",
    "        super().__init__()\n",
    "        assert nlayers >= 1\n",
    "        ### START CODE HERE ### (≈ 11 lines of code)\n",
    "       \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "def test_head():\n",
    "    hparams = [\n",
    "        (10, 20),\n",
    "        (64, 32, 4, 256, 16),\n",
    "        (20, 10, 1)\n",
    "    ]\n",
    "    num_params = [\n",
    "        336512,\n",
    "        152848,\n",
    "        3968]\n",
    "    for p, s in zip(hparams, num_params):\n",
    "        head = DINOHead(*p)\n",
    "        assert sum(p.numel() for p in head.parameters() if p.requires_grad) == s\n",
    "        y = head(torch.randn(32, p[0]))\n",
    "        assert y.shape == (32, p[1])\n",
    "    print(\"Head test successful\")\n",
    "\n",
    "test_head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we wrap the ViT and the DINO head in a single model.\n",
    "We also provide an EMA wrapper like in previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTTinyDINO(nn.Module):\n",
    "    def __init__(self, out_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = vit_tiny()\n",
    "        in_dim = 192 # Output dimension of the vit_tiny\n",
    "        # Empirically values like these work quite well\n",
    "        self.head = DINOHead(\n",
    "            in_dim=in_dim,\n",
    "            out_dim=out_dim,\n",
    "            nlayers=3,\n",
    "            hidden_dim=in_dim * 2,\n",
    "            bottleneck_dim=in_dim // 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAWrapper(nn.Module):\n",
    "    def __init__(self, student, teacher, momentum=0.992):\n",
    "        super().__init__()\n",
    "        self.momentum = momentum\n",
    "        teacher.load_state_dict(student.state_dict())\n",
    "        self.model = teacher\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def update(self, student):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            student_param = student.state_dict()[name]\n",
    "            param.data *= self.momentum\n",
    "            param.data += (1 - self.momentum) * student_param\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. The Loss Function\n",
    "\n",
    "Implement the DINO loss function.\n",
    "Remember that the DINO loss uses *centering* and *sharpening*.\n",
    "For the centering you need to save the current center in a tensor (you should use `register_buffer` in the `__init__ `function for this).\n",
    "For the sharpening you need to divide the ouput of the heads by the appropriate temperatures.\n",
    "\n",
    "The DINO loss is the mean of the cross entropy losses between the student output (local + global views) and the teacher output (global views only).\n",
    "However, do not compute the cross entropy loss for outputs of the student and teacher that correspond to the same view.\n",
    "\n",
    "The input to the loss function will be flattened in the first dimension:\n",
    "`teacher_output` has shape `(batch_size * num_global, out_dim)` and `num_global` entries in a row correspond to the global views of the same image.\n",
    "You will need to group them somehow to compute the loss between views.\n",
    "One way to achieve this is using `torch.chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINOLoss(nn.Module):\n",
    "    def __init__(self,\n",
    "                 out_dim,\n",
    "                 num_global=2,\n",
    "                 num_local=2,\n",
    "                 student_temp=0.1,\n",
    "                 center_momentum=0.9):\n",
    "        super().__init__()\n",
    "        self.num_global = num_global\n",
    "        self.num_local = num_local\n",
    "        self.student_temp = student_temp\n",
    "        self.center_momentum = center_momentum\n",
    "\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _update_center(self, teacher_output):\n",
    "        \"\"\"\n",
    "        Update the center used for centering the outputs using exponential moving average.\n",
    "        Args:\n",
    "            teacher_output: Tensor of shape (batch_size * num_global, out_dim)\n",
    "        \"\"\"\n",
    "        ## START CODE HERE ### (≈ 2 lines of code)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "\n",
    "    def forward(self, student_output, teacher_output, teacher_temp):\n",
    "        \"\"\"\n",
    "        Compute the DINO loss given the outputs of the student and teacher networks.\n",
    "        Args:\n",
    "            student_output: Tensor of shape (batch_size * (num_global + num_local), out_dim)\n",
    "            teacher_output: Tensor of shape (batch_size * num_global, out_dim)\n",
    "            teacher_temp: Teacher temperature for this step\n",
    "\n",
    "        Returns: scalar tensor, the loss value\n",
    "        \"\"\"\n",
    "        # Don't forgot the centering and sharpening terms, as well as to update the center\n",
    "        ### START CODE HERE ### (≈ 15 lines of code)\n",
    "       \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "from functools import partial\n",
    "\n",
    "def test_dinoloss():\n",
    "    loss = DINOLoss(out_dim=8, num_global=2, num_local=3, student_temp=0.1, center_momentum=0.5)\n",
    "    student_output = torch.linspace(-1, 1, 160).view(5*4, 8)\n",
    "    teacher_output = torch.linspace(0, 2, 64).view(2*4, 8)\n",
    "\n",
    "    c0 = torch.tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "    c1 = torch.tensor([0.4444, 0.4603, 0.4762, 0.4921, 0.5079, 0.5238, 0.5397, 0.5556])\n",
    "    c2 = torch.tensor([0.6667, 0.6905, 0.7143, 0.7381, 0.7619, 0.7857, 0.8095, 0.8333])\n",
    "    c3 = torch.tensor([0.7778, 0.8056, 0.8333, 0.8611, 0.8889, 0.9167, 0.9444, 0.9722])\n",
    "\n",
    "    t1, t2, t3 = [0.05, 0.08, 0.1]\n",
    "    l1 = torch.tensor(1.8159)\n",
    "    l2 = torch.tensor(1.9949)\n",
    "    l3 = torch.tensor(2.0686)\n",
    "\n",
    "    close = partial(torch.allclose, atol=1e-4, rtol=1e-4)\n",
    "\n",
    "    assert close(loss.center, c0)\n",
    "    for c, l, t in zip([c1, c2, c3], [l1, l2, l3], [t1, t2, t3]):\n",
    "        assert close(loss(student_output, teacher_output, teacher_temp=t), l)\n",
    "        assert close(loss.center, c)\n",
    "    print(\"Loss test successful!\")\n",
    "\n",
    "test_dinoloss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III. The Dataset and Augmentations\n",
    "\n",
    "[medmnist](https://medmnist.com/) provides a number of medical imaging datasets and is available as a pip package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = medmnist.PathMNIST(split='train', download=True, transform=transforms.ToTensor())\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "imgs = [train_set[i][0] for i in range(32)]\n",
    "grid = make_grid(imgs, nrow=8)\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(grid.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local and Global Views\n",
    "\n",
    "The DINO paper uses a combination of local and global views of the images.\n",
    "To enforce a local-global correspondence, the local views (only seen by the student) are random crops of the images and the global views are the entire images.\n",
    "\n",
    "We will use very similar augmentations to the paper. In particular, we will have three types of augmentations:\n",
    "- **Global 1**:\n",
    "    - Color jitter with probability 80%\n",
    "    - Horizontal flip with probability 50%\n",
    "    - Vertical flip with probability 50%\n",
    "    - Gaussian blur with probability 100%\n",
    "- **Global 2**:\n",
    "    - Color jitter with probability 80%\n",
    "    - Horizontal flip with probability 50%\n",
    "    - Vertical flip with probability 50%\n",
    "    - Gaussian blur with probability 10%\n",
    "    - Solarization (threshold 0.5) with probability 20%\n",
    "- **Local**:\n",
    "    - Color jitter with probability 80%\n",
    "    - Horizontal flip with probability 50%\n",
    "    - Vertical flip with probability 50%\n",
    "    - Gaussian blur with probability 50%\n",
    "    - Random sized crop of size between 0.2 and 0.8 of the original image size with probability 100%\n",
    "\n",
    "The augmentations are applied in the order listed above. Normalization is applied to all views after the augmentations.\n",
    "In the `__getitem__` method the augmentations are applied to an image.\n",
    "Global 1 and Global 2 augmentations are applied at least once, the other `num_global - 2` times they are chosen randomly.\n",
    "The local augmentations are applied `num_local` times.\n",
    "All the augmentations are stacked together resulting in a tensor of shape `(num_global + num_local, c, h, w)`.\n",
    "\n",
    "Since these images are quite different from ImageNet, other augmentations might be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalGlobalPathMNIST(medmnist.PathMNIST):\n",
    "    # Precomputed from the PathMNIST train set\n",
    "    NORMALIZE = transforms.Normalize(\n",
    "        std=[0.1237, 0.1768, 0.1244],\n",
    "        mean=[0.7405, 0.5330, 0.7058],\n",
    "    )\n",
    "\n",
    "    def __init__(self, split='train', num_local=2, num_global=2):\n",
    "        super().__init__(split=split)\n",
    "        assert num_local >= 1\n",
    "        assert num_global >= 2\n",
    "        self.num_local = num_local\n",
    "        self.num_global = num_global\n",
    "\n",
    "        jitter = transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)\n",
    "        gaussian_blur = transforms.GaussianBlur(5, sigma=(0.1, 1.0))\n",
    "\n",
    "        ### START CODE HERE ### (≈ 4 lines of code)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Gets views of the image at the given index.\n",
    "\n",
    "        Returns: Tensor of shape (num_global + num_local, 3, 28, 28)\n",
    "        \"\"\"\n",
    "        img, _ = super().__getitem__(idx)\n",
    "        ### START CODE HERE ### (≈ 9 lines of code)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "def test_local_global():\n",
    "    dataset = LocalGlobalPathMNIST(num_local=6, num_global=2)\n",
    "    imgs = [dataset[i] for i in range(32)]\n",
    "    assert all([img.shape == (8, 3, 28, 28) for img in imgs])\n",
    "\n",
    "    dataset = LocalGlobalPathMNIST(num_local=4, num_global=3)\n",
    "    imgs = [dataset[i] for i in range(32)]\n",
    "    assert all([img.shape == (7, 3, 28, 28) for img in imgs])\n",
    "    print(\"Local and global views test successful\")\n",
    "\n",
    "test_local_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some examples of local and global views.\n",
    "Each row is a different image. The first two columns are the global views and the last 2 columns are the local views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  LocalGlobalPathMNIST()\n",
    "loader = DataLoader(dataset, batch_size=4)\n",
    "imgs = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = LocalGlobalPathMNIST.NORMALIZE.mean, LocalGlobalPathMNIST.NORMALIZE.std\n",
    "unnormalize = transforms.Normalize(\n",
    "    mean=[-m / s for m, s in zip(mean, std)],\n",
    "    std=[1 / s for s in std]\n",
    ")\n",
    "\n",
    "\n",
    "imgs = imgs.view(-1, 3, 28, 28)\n",
    "imgs = unnormalize(imgs).clamp(0, 1)\n",
    "grid = make_grid(imgs, nrow=4)\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.axis('off')\n",
    "plt.imshow(grid.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DINO training uses cosine schedulers not only for the learning rate, but also for the weight decay, the teacher EMA momentum and the teacher temperature.\n",
    "For more information about weight decay scheduling see https://arxiv.org/abs/2011.11152, https://arxiv.org/abs/2006.08643.\n",
    "\n",
    "These extra tricks are not necessary for training the tiny ViT for a small amount of time, but we will use them for the exercise's sake.\n",
    "Familiarize yourself with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_schedule(base_value, final_value, total_steps, warmup_steps=0, start_warmup_value=0):\n",
    "    warmup_schedule = np.array([])\n",
    "    if warmup_steps > 0:\n",
    "        warmup_schedule = np.linspace(start_warmup_value, base_value, warmup_steps)\n",
    "\n",
    "    iters = np.arange(total_steps - warmup_steps)\n",
    "    schedule = final_value + 0.5 * (base_value - final_value) * (1 + np.cos(np.pi * iters / len(iters)))\n",
    "\n",
    "    schedule = np.concatenate((warmup_schedule, schedule))\n",
    "    assert len(schedule) == total_steps\n",
    "    return schedule\n",
    "\n",
    "class CosineSchedule:\n",
    "    def __init__(\n",
    "            self,\n",
    "            base_value: float,\n",
    "            final_value: Optional[float] = None,\n",
    "            warmup_pct: float = 0,\n",
    "            start_warmup_value: float = 0):\n",
    "        self.schedule = None\n",
    "        self.total_steps = None\n",
    "\n",
    "        self.base_value = base_value\n",
    "        self.final_value = final_value if final_value is not None else base_value\n",
    "        self.warmup_pct = warmup_pct\n",
    "        self.start_warmup_value = start_warmup_value\n",
    "\n",
    "    def init(self, total_steps: int):\n",
    "        self.schedule = cosine_schedule(\n",
    "            base_value=self.base_value,\n",
    "            final_value=self.final_value,\n",
    "            total_steps=total_steps,\n",
    "            warmup_steps=int(self.warmup_pct * total_steps),\n",
    "            start_warmup_value=self.start_warmup_value\n",
    "        )\n",
    "        self.total_steps = total_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        if self.schedule is None:\n",
    "            raise ValueError(\"Schedule not initialized\")\n",
    "        step = min(step, self.total_steps - 1)\n",
    "        return self.schedule[step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear warmup from 0 to 0.5 in 10% of the steps, then cosine decay to 0.1\n",
    "schedule = CosineSchedule(0.5, 0.1, 0.1, 0)\n",
    "# 100 steps total\n",
    "schedule.init(100)\n",
    "plt.plot([schedule(i) for i in range(110)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will wrap the training logic in a class.\n",
    "The trainer will only see the global views, you will need to slice the batch appropriately.\n",
    "\n",
    "Use the [AdamW](https://arxiv.org/abs/1711.05101) optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINOTrainer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: LocalGlobalPathMNIST,\n",
    "            lr_schedule: Callable[[int], float],\n",
    "            wd_schedule: Callable[[int], float],\n",
    "            teacher_temp_schedule: Callable[[int], float],\n",
    "            teacher_ema_schedule: Callable[[int], float],\n",
    "            student_temp: float = 0.1,\n",
    "            batch_size: int = 256,\n",
    "            out_dim: int = 256,\n",
    "            ckpt_name: Union[str, os.PathLike] = \"checkpoint.pth\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ckpt_name = Path(ckpt_name)\n",
    "\n",
    "        self.epoch = 0\n",
    "        self.steps = 0\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.lr_schedule = lr_schedule\n",
    "        self.wd_schedule = wd_schedule\n",
    "        self.teacher_temp_schedule = teacher_temp_schedule\n",
    "        self.teacher_ema_schedule = teacher_ema_schedule\n",
    "\n",
    "        self.num_local = dataset.num_local\n",
    "        self.num_global = dataset.num_global\n",
    "\n",
    "        self.data_loader = DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        # Initialize the student and the teacher, optimizer and the loss. Don't forget the EMA wrapper!\n",
    "        ### START CODE HERE ### (≈ 5 lines of code)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.student.parameters()).device\n",
    "\n",
    "    def train_one_epoch(self, epoch):\n",
    "        self.student.train()\n",
    "        self.teacher.train()\n",
    "        num_global = self.dataset.num_global\n",
    "        with tqdm(self.data_loader, desc=f'Epoch: {epoch}') as pbar:\n",
    "            for batch in pbar:\n",
    "                batch = batch.transpose(0, 1).contiguous()\n",
    "                # batch has shape (num_global + num_local, bs, c, h, w)\n",
    "                c, h, w = batch.shape[-3:]\n",
    "\n",
    "                # Apply the various schedules, compute the student and teacher output and the loss.\n",
    "                # Update the student using the optimizer and the teacher using the EMA wrapper functionality.\n",
    "                \n",
    "                ### START CODE HERE ### (≈ 12 lines of code)\n",
    "               \n",
    "                ### END CODE HERE ###\n",
    "\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                self.steps += 1\n",
    "\n",
    "    def save(self):\n",
    "        torch.save(dict(\n",
    "            student=self.student.state_dict(),\n",
    "            teacher=self.teacher.state_dict(),\n",
    "            optim=self.optim.state_dict(),\n",
    "            dino_loss=self.dino_loss.state_dict(),\n",
    "            epoch=self.epoch,\n",
    "            steps=self.steps,\n",
    "        ), self.ckpt_name)\n",
    "\n",
    "    def load(self):\n",
    "        print('Loading checkpoint', self.ckpt_name)\n",
    "        ckpt = torch.load(self.ckpt_name)\n",
    "        self.student.load_state_dict(ckpt['student'])\n",
    "        self.teacher.load_state_dict(ckpt['teacher'])\n",
    "        self.optim.load_state_dict(ckpt['optim'])\n",
    "        self.dino_loss.load_state_dict(ckpt['dino_loss'])\n",
    "        self.epoch = ckpt['epoch']\n",
    "        self.steps = ckpt['steps']\n",
    "\n",
    "    def train(self, num_epochs: int, resume=False):\n",
    "        self.epoch = 0\n",
    "        self.steps = 0\n",
    "\n",
    "        total_iters = len(self.data_loader) * num_epochs\n",
    "        self.lr_schedule.init(total_iters)\n",
    "        self.wd_schedule.init(total_iters)\n",
    "        self.teacher_temp_schedule.init(total_iters)\n",
    "        self.teacher_ema_schedule.init(total_iters)\n",
    "\n",
    "        if resume and self.ckpt_name.exists():\n",
    "            self.load()\n",
    "\n",
    "        while self.epoch < num_epochs:\n",
    "            self.train_one_epoch(self.epoch)\n",
    "            self.epoch += 1\n",
    "            self.save()\n",
    "\n",
    "        return self.teacher.model.encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the schedules for the various hyperparameters.\n",
    "- The weight decay follows a cosine schedule from 0.02 to 0.04.\n",
    "- The learning rate follows a cosine schedule from 5e-4 to 2e-4 with a warmup of 10% of the total number of iterations.\n",
    "- The teacher temperature warms up from 0.04 to 0.07 with a warmup of 10% of the total number of iterations and then stays constant.\n",
    "- The teacher EMA momentum follows a cosine schedule from 0.992 to 0.996."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 4 lines of code)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LOCAL = 2\n",
    "NUM_GLOBAL = 2\n",
    "BATCH_SIZE = 256\n",
    "OUT_DIM = 256\n",
    "NUM_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LocalGlobalPathMNIST(\n",
    "    num_local=NUM_LOCAL,\n",
    "    num_global=NUM_GLOBAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DINOTrainer(\n",
    "    dataset=dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    out_dim=OUT_DIM,\n",
    "    lr_schedule=lr_schedule,\n",
    "    wd_schedule=wd_schedule,\n",
    "    teacher_temp_schedule=teacher_temp_schedule,\n",
    "    teacher_ema_schedule=ema_schedule).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should take around ~45 minutes.\n",
    "# The loss might decrease very slowly at the beginning of training.\n",
    "# If this takes too long, feel free to interrupt the training, but try to run at least 5 epochs.\n",
    "encoder = trainer.train(NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V. Evaluation\n",
    "As usual, we evaluate the model by computing the knn accuracy on the test set.\n",
    "The encoder returned by the trainer is the teacher ViT without the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = medmnist.PathMNIST(split='train', download=True,\n",
    "                               transform=transforms.Compose([transforms.ToTensor(), LocalGlobalPathMNIST.NORMALIZE]))\n",
    "test_set = medmnist.PathMNIST(split='test', download=True,\n",
    "                              transform=transforms.Compose([transforms.ToTensor(), LocalGlobalPathMNIST.NORMALIZE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_features(encoder, dataset, device):\n",
    "    encoder.eval()\n",
    "    loader = DataLoader(dataset, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    features = []\n",
    "    labels = []\n",
    "    for image, label in tqdm(loader):\n",
    "        image = image.to(device)\n",
    "        features.append(encoder(image).cpu())\n",
    "        labels.append(label.cpu())\n",
    "    features = torch.cat(features)\n",
    "    features /= features.norm(dim=-1, keepdim=True)\n",
    "    labels = torch.cat(labels).squeeze()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_knn(encoder, train_set, test_set, device):\n",
    "    train_features, train_labels = get_features(encoder, train_set, device)\n",
    "    test_features, test_labels = get_features(encoder, test_set, device)\n",
    "    nn_idc = (test_features @ train_features.T).argmax(dim=-1)\n",
    "    preds = train_labels[nn_idc]\n",
    "    return (preds == test_labels).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get around 75% accuracy. This is not particularly good. In fact a small ResNet trained supervised on ImageNet will get around 80% accuracy. However, the DINO model can be improved by much longer training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_knn(encoder, train_set, test_set, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI. Investigate the pseudo-label distribution\n",
    "\n",
    "It the turns out, the pseudo labels (produced by the output of the projection head) are not uniformly distributed. Display the number of images assigned to each class in a histogram (tip: use `torch.bincount`). What do you observe? Why do you think this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈ 5 lines of code)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
