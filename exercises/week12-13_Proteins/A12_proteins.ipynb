{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HHU Deep Learning, SS2022/23, 05.05.2023, Prof. Dr. Markus Kollmann\n",
    "\n",
    "Lecturers and Tutoring is done by Tim Kaiser, Nikolas Adaloglou and Felix Michels.\n",
    "\n",
    "# Assignment 13 - Protein Structure Prediction\n",
    "\n",
    "Pytorch test_val.pt file: https://uni-duesseldorf.sciebo.de/s/lkXGy1oECxa7oKF\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. Package installations and imports\n",
    "2. Post-process attention maps\n",
    "3. Predict contacts from attention maps\n",
    "4. Data loading\n",
    "5. Train a linear layer to predict contact maps from ESM embeddings\n",
    "\n",
    "---\n",
    "\n",
    "# Introduction\n",
    "\n",
    "In this assignment you will use the pretrained [ESM](https://github.com/facebookresearch/esm) protein language model to predict protein contacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Package installations and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install biopython biotite\n",
    "\n",
    "!curl -O https://raw.githubusercontent.com/facebookresearch/esm/main/examples/data/1a3a_1_A.a3m\n",
    "!curl -O https://raw.githubusercontent.com/facebookresearch/esm/main/examples/data/5ahw_1_A.a3m\n",
    "!curl -O https://raw.githubusercontent.com/facebookresearch/esm/main/examples/data/1xcr_1_A.a3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:51:42.784648539Z",
     "start_time": "2023-06-29T19:51:42.658175174Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "from biotite.structure.io.pdbx import PDBxFile, get_structure\n",
    "from biotite.database import rcsb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:51:57.083279356Z",
     "start_time": "2023-06-29T19:51:42.779089794Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download and load the models\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_model(name):\n",
    "    model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", name)\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval()\n",
    "    head = model.contact_head.regression\n",
    "    return model, alphabet, batch_converter, head\n",
    "\n",
    "# Download the models. This can take some time (~9GB of weights)\n",
    "get_model(name=\"esm2_t33_650M_UR50D\")\n",
    "model, alphabet, batch_converter, head = get_model(name=\"esm1_t34_670M_UR50S\")\n",
    "print(f\"padding_idx:{model.padding_idx}, cls_idx:{model.cls_idx}, eos_idx:{model.eos_idx}, mask_idx:{model.mask_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_model` function also returns a `batch_converter`, which takes a list of (protein name, amino acid sequence) tuples and returns a tokenized batch including padding and special tokens.\n",
    "The relevant special tokens are `alphabet.cls_token` (if `alphabet.prepend_bos` is `True`), `alphabet.eos_token` (if `alphabet.append_eos` is `True`) as well `alphabet.mask_token`.\n",
    "(These values are also attributes of the model, e.g. `model.cls_idx`.)\n",
    "\n",
    "The forward function requires the paramter `need_head_weights=True` to return the attention maps in the `results` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:52:37.997472514Z",
     "start_time": "2023-06-29T19:52:37.287530998Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"protein1\", \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"),\n",
    "    (\"protein3\",  \"K A <mask> I S Q\"),\n",
    "]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "batch_mask = (batch_tokens != alphabet.padding_idx)\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    model = model.to(DEVICE)\n",
    "    batch_tokens = batch_tokens.to(DEVICE)\n",
    "    results = model(batch_tokens, need_head_weights=True)\n",
    "\n",
    "print(f\"The model returns the attention maps for all layers and heads with shape [batch_size, layers, heads, seq_length, seq_length]  == {results['attentions'].shape}\")\n",
    "print(f\"as well as the output representations for each token/residue in the seq with shape [batch_size, seq_length, d_model]  == {results['logits'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Post-process attention maps\n",
    "\n",
    "The attention maps -- unlike the contact maps -- are generally not symmetric.\n",
    "We symmetrize an attention map $A \\in [0, 1]^{L \\times L}$ by computing\n",
    "$$A^\\text{sym} = A + A^\\top.$$\n",
    "To reduce biases for specific positions we use a form of average product correction (APC), which is defined as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "a_i &= \\sum_{j=1}^L A_{ij} \\quad\\text{ for } i = 1, \\ldots, L \\\\\n",
    "a &= \\sum_{i=1}^L\\sum_{j=1}^L A_{ij} \\\\\n",
    "A^\\text{APC}_{ij} &= A_{ij} - \\frac{a_i a_j}{a}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "The input of the functions `symmetrize` and `apc` can have arbitrary many batch and channel dimensions in the front, make sure to only apply the operations to the last two dimensions (use `dim=-1` and `dim=-2` in the appropriate places).\n",
    "\n",
    "The `postprocess_attention` function takes the attention maps of shape `(batch_size, layers, heads, L, L)` and performs the following steps:\n",
    "- If appropiate (`append_eos` is `True`), the eos token attentions are removed.\n",
    "This is done by setting the corresponding attention values to zero and removing the last row and column of the attention maps.\n",
    "- If appropiate (`remove_cls` is `True`), the cls token attentions are removed by removing the first row and column of the attention maps.\n",
    "- Only keep the last `last_n_layers` layers. If `last_n_layers` is `None`, all layers are kept.\n",
    "- Apply the `symmetrize` and `apc` functions in that order.\n",
    "- Reshape and permute as necessary to obtain a tensor of shape `(batch_size, L', L', last_n_layers * heads)`,\n",
    "where `L'` is the sequence length after possibly removing eos and cls tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:53:29.754283367Z",
     "start_time": "2023-06-29T19:53:29.571799904Z"
    }
   },
   "outputs": [],
   "source": [
    "def symmetrize(x):\n",
    "    \"\"\"Make layer symmetric in final two dimensions, used for contact prediction.\"\"\"\n",
    "    ### START CODE HERE ### (≈ 1 lines of code)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "def apc(x):\n",
    "    \"\"\"Perform average product correct, used for contact prediction.\"\"\"\n",
    "    ### START CODE HERE ### (≈ 6 lines of code)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "def postprocess_attention(attentions, append_eos=False, eos_idx=None, tokens=None, remove_cls=True, last_n_layers=None):\n",
    "    \"\"\"If append_eos is True, eos_idx and tokens must be specified.\"\"\"\n",
    "    ### START CODE HERE ### (≈ 13 lines of code)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return attentions\n",
    "\n",
    "\n",
    "test_func(symmetrize)\n",
    "test_func(apc)\n",
    "test_func(postprocess_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the attention maps for the two sequences in the batch above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:54:16.488650733Z",
     "start_time": "2023-06-29T19:54:16.060599428Z"
    }
   },
   "outputs": [],
   "source": [
    "contact_maps = postprocess_attention(results['attentions'])\n",
    "mean_map = contact_maps.mean(-1).cpu().numpy()\n",
    "print(f\"contact_maps.shape = {contact_maps.shape}, mean_map.shape = {mean_map.shape}\")\n",
    "# Visualize the mean self-attention map for contact prediction\n",
    "for (_, seq), tokens_len, attention_contacts in zip(data, batch_lens, mean_map):\n",
    "    plt.matshow(attention_contacts[: tokens_len, :tokens_len], cmap=\"viridis\")\n",
    "    plt.title(seq)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III. Predict contacts from attention maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:55:23.710806775Z",
     "start_time": "2023-06-29T19:55:21.188172393Z"
    }
   },
   "outputs": [],
   "source": [
    "# We load the three sequences we downloaded at the beginning of the notebook\n",
    "\n",
    "def get_data(PDB_IDS):\n",
    "    structures = {\n",
    "        name.lower(): get_structure(PDBxFile.read(rcsb.fetch(name, \"cif\")))[0]\n",
    "        for name in PDB_IDS}\n",
    "    contacts = { name: contacts_from_pdb(structure, chain=\"A\") \n",
    "        for name, structure in structures.items()}\n",
    "    msas = { name: read_msa(f\"{name.lower()}_1_A.a3m\")\n",
    "        for name in PDB_IDS}\n",
    "    sequences = { name: msa[0] for name, msa in msas.items()}\n",
    "    return sequences, contacts \n",
    "\n",
    "PDB_IDS = [\"1a3a\", \"5ahw\", \"1xcr\"]\n",
    "sequences, contacts = get_data(PDB_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T19:55:23.712453590Z",
     "start_time": "2023-06-29T19:55:23.667392164Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test the two ESM models with their trained linear heads to predict contacts from the attention maps.\n",
    "\n",
    "The `predict_contact_maps` function must do the following steps:\n",
    "- Convert the sequence to tokens (remember that `batch_converter` expects a list of sequences)\n",
    "- Pass the tokens through the model and obtain the attention maps and apply postprocessing\n",
    "- If `head` is `None`, compute the mean attention map over all heads and return it\n",
    "- Otherwise, apply the `head` to the attention maps followed by a sigmoid and return the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_contact_maps(model, alphabet, batch_converter, sequence, device, head=None):\n",
    "    \"\"\"Predict contact maps from a single sequence.\n",
    "    If head is None, the mean attention map will be computed.\n",
    "\n",
    "    Returns a tensor of shape (L,L)\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### (≈ 6 lines of code)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_unsup_maps(model, alphabet, batch_converter, sequences, device, head=None):\n",
    "    if head is None:\n",
    "        print(\"Warning: mean attention maps will be computed as contact maps\")\n",
    "    predictions = {}\n",
    "    results = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    for name, inputs in sequences.items():\n",
    "        out = predict_contact_maps(model, alphabet, batch_converter, inputs, device, head=head)\n",
    "\n",
    "        predictions[name] = out.cpu()\n",
    "        metrics = {\"id\": name, \"model\": \"ESM (Unsupervised)\"}\n",
    "        metrics.update(evaluate_prediction(predictions[name], contacts[name]))\n",
    "        results.append(metrics)\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=(18, 6), ncols=3)\n",
    "    for ax, name in zip(axes, PDB_IDS):\n",
    "        prediction = predictions[name]\n",
    "        target = contacts[name]\n",
    "        plot_contacts_and_predictions(\n",
    "            prediction, target, ax=ax, title = lambda prec: f\"{name}: Long Range P@L: {100 * prec:0.1f}\")\n",
    "    plt.show()\n",
    "    return results\n",
    "\n",
    "# esm 2\n",
    "model, alphabet, batch_converter, head = get_model(name=\"esm2_t33_650M_UR50D\")\n",
    "print(f\"padding_idx:{model.padding_idx}, cls_idx:{model.cls_idx}, eos_idx:{model.eos_idx}, mask_idx:{model.mask_idx}\")\n",
    "results2 = predict_unsup_maps(model, alphabet, batch_converter, sequences, device=DEVICE, head=head)\n",
    "display(results2)\n",
    "\n",
    "# esm 1\n",
    "model, alphabet, batch_converter, head = get_model(name=\"esm1_t34_670M_UR50S\")\n",
    "print(f\"padding_idx:{model.padding_idx}, cls_idx:{model.cls_idx}, eos_idx:{model.eos_idx}, mask_idx:{model.mask_idx}\")\n",
    "results1 = predict_unsup_maps(model, alphabet, batch_converter, sequences, device=DEVICE, head=head)\n",
    "display(results1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results\n",
    "\n",
    "#### ESM2\n",
    "| id   | model              |   local_AUC |   local_P@L |   local_P@L2 |   local_P@L5 |   short_AUC |   short_P@L |   short_P@L2 |   short_P@L5 |   medium_AUC |   medium_P@L |   medium_P@L2 |   medium_P@L5 |   long_AUC |   long_P@L |   long_P@L2 |   long_P@L5 |\n",
    "|:-----|:-------------------|------------:|------------:|-------------:|-------------:|------------:|------------:|-------------:|-------------:|-------------:|-------------:|--------------:|--------------:|-----------:|-----------:|------------:|------------:|\n",
    "| 1a3a | ESM (Unsupervised) |    0.801181 |    0.662069 |     0.805556 |     0.896552 |    0.528245 |    0.296552 |     0.5      |     0.827586 |     0.612222 |     0.344828 |      0.569444 |      0.931035 |   0.806507 |   0.689655 |    0.791667 |    0.931035 |\n",
    "| 5ahw | ESM (Unsupervised) |    0.819763 |    0.68     |     0.83871  |     0.96     |    0.543314 |    0.296    |     0.5      |     0.84     |     0.569258 |     0.304    |      0.548387 |      0.92     |   0.937361 |   0.864    |    0.951613 |    0.96     |\n",
    "| 1xcr | ESM (Unsupervised) |    0.529522 |    0.351438 |     0.5      |     0.693548 |    0.344734 |    0.204473 |     0.320513 |     0.516129 |     0.410161 |     0.265176 |      0.365385 |      0.596774 |   0.576668 |   0.408946 |    0.544872 |    0.758065 |\n",
    "\n",
    "\n",
    "#### ESM1\n",
    "| id   | model              |   local_AUC |   local_P@L |   local_P@L2 |   local_P@L5 |   short_AUC |   short_P@L |   short_P@L2 |   short_P@L5 |   medium_AUC |   medium_P@L |   medium_P@L2 |   medium_P@L5 |   long_AUC |   long_P@L |   long_P@L2 |   long_P@L5 |\n",
    "|:-----|:-------------------|------------:|------------:|-------------:|-------------:|------------:|------------:|-------------:|-------------:|-------------:|-------------:|--------------:|--------------:|-----------:|-----------:|------------:|------------:|\n",
    "| 1a3a | ESM (Unsupervised) |    0.473591 |    0.358621 |     0.458333 |     0.62069  |    0.428934 |    0.241379 |     0.375    |     0.655172 |     0.486386 |     0.296552 |      0.430556 |      0.758621 |  0.472737  |   0.393103 |   0.486111  |   0.448276  |\n",
    "| 5ahw | ESM (Unsupervised) |    0.658321 |    0.512    |     0.645161 |     0.8      |    0.508541 |    0.28     |     0.451613 |     0.88     |     0.55529  |     0.328    |      0.564516 |      0.76     |  0.942871  |   0.84     |   0.983871  |   1         |\n",
    "| 1xcr | ESM (Unsupervised) |    0.211544 |    0.162939 |     0.198718 |     0.274194 |    0.169886 |    0.118211 |     0.160256 |     0.241935 |     0.169768 |     0.118211 |      0.179487 |      0.209677 |  0.0334794 |   0.028754 |   0.0320513 |   0.0483871 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of data\n",
    "\n",
    "Contact maps are only half of the story. To really know the structure of a protein we must know the 3D coordinates of each amino acid (or more precisely, of the $C_\\beta$ atoms of the amino acids).\n",
    "\n",
    "The contact maps are obtained by taking the 3D coordinates of each atom and calculating the distance between them. If the distance is less than a threshold, then the two atoms are said to be in contact. The threshold is usually set to 8 Angstroms.\n",
    "\n",
    "Instead of using a binary threshold we can also bin the distances to obtain a *distogram*.\n",
    "The distogram contains the structure information of the protein in an rotation and translation invariant way.\n",
    "\n",
    "You will use the `esm_structural_train` and `esm_structural_valid` datasets in the rest of the exercise.\n",
    "Each element of these datasets is a dictionary including the following keys:\n",
    "- `seq`: the sequence of the protein (string length L)\n",
    "- `dist`: the distances between the amino acids (numpy arrary of shape L x L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_level = \"superfamily\"\n",
    "cv_partition ='4'\n",
    "\n",
    "esm_structural_train = ESMStructuralSplitDataset(\n",
    "            split_level=split_level,\n",
    "            cv_partition=cv_partition,\n",
    "            split='train',\n",
    "            root_path = os.path.expanduser('~/.cache/torch/data/esm'),\n",
    "            download=True)\n",
    "esm_structural_valid = ESMStructuralSplitDataset(\n",
    "            split_level=split_level,\n",
    "            cv_partition=cv_partition,\n",
    "            split='valid',\n",
    "            root_path = os.path.expanduser('~/.cache/torch/data/esm'),\n",
    "            download=True)\n",
    "\n",
    "def visualize_coords(coords):\n",
    "    xs = coords[:,0]\n",
    "    ys = coords[:,1]\n",
    "    zs = coords[:,2]\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111,  projection='3d')\n",
    "    ax.set_title('3D coordinates of $C_{b}$ backbone structure')\n",
    "    N = coords.shape[0]\n",
    "\n",
    "    for i in range(coords.shape[0] - 1):\n",
    "        ax.plot(\n",
    "            xs[i:i+2], ys[i:i+2], zs[i:i+2],\n",
    "            color=plt.cm.viridis(i/N),\n",
    "            marker='o')\n",
    "\n",
    "def visualize_dist_contact_map(dist, threshold=8):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    sns.heatmap(dist, ax=ax[0])\n",
    "    sns.heatmap(dist<threshold, ax=ax[1])\n",
    "    ax[0].set_title('Distance Map')\n",
    "    ax[1].set_title('Contact Map')\n",
    "\n",
    "\n",
    "print(f\"Validation data: {len(esm_structural_valid)} sequences, Training data: {len(esm_structural_train)} sequences\")\n",
    "ele = esm_structural_train[0]\n",
    "target = ele[\"dist\"]\n",
    "target = torch.from_numpy((target<8)).float()\n",
    "\n",
    "coords = ele['coords']\n",
    "visualize_coords(coords)\n",
    "visualize_dist_contact_map(ele['dist'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV. Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `DatasetAttMap` class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetAttMap(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, contact_maps=True, max_len=500):\n",
    "        self.dataset = dataset\n",
    "        self.alphabet = alphabet\n",
    "        self.contact_maps = contact_maps\n",
    "        self.crop_max_len_data(max_len)\n",
    "\n",
    "    def crop_max_len_data(self, max_len):\n",
    "        # Remove all sequences longer than max_len from `self.dataset`\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a triplet of (idx, seq, target) where:\n",
    "            - idx: the index of the sequence in the dataset\n",
    "            - seq: the sequence of the protein (string length L)\n",
    "            - target: either the distance map (float torch.Tensor) if contact_map=True or the contact map (long torch.Tensor) if contact_map=False\n",
    "        Compute the contact map using the 8 Angstrom threshold as described above.\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ### (≈ 7 lines of code)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def get_batch_indices(self, toks_per_batch):\n",
    "        \"\"\" Return a list of batches of indices corresponding to sequences of similar length\"\"\"\n",
    "        sizes = [(len(s[\"seq\"]), i) for i, s in enumerate(self.dataset)]\n",
    "        sizes.sort()\n",
    "        batches = []\n",
    "        buf = []\n",
    "        max_len = 0\n",
    "\n",
    "        def _flush_current_buf():\n",
    "            nonlocal max_len, buf\n",
    "            if len(buf) == 0:\n",
    "                return\n",
    "            batches.append(buf)\n",
    "            buf = []\n",
    "            max_len = 0\n",
    "\n",
    "        for sz, i in sizes:\n",
    "            if max(sz, max_len) * (len(buf) + 1) > toks_per_batch:\n",
    "                _flush_current_buf()\n",
    "            max_len = max(max_len, sz)\n",
    "            buf.append(i)\n",
    "\n",
    "        _flush_current_buf()\n",
    "        random.shuffle(batches)\n",
    "        return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your code and set the training hyperparameters\n",
    "# We will use the provided `BatchConverterContact`\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_att_map(tokens, model, alphabet, last_n_layers):\n",
    "    att_maps = postprocess_attention(model(tokens, need_head_weights=True)[\"attentions\"],\n",
    "        append_eos=alphabet.append_eos, eos_idx=alphabet.eos_idx, tokens=batch_tokens,\n",
    "        remove_cls=alphabet.prepend_bos, last_n_layers=last_n_layers)\n",
    "    return att_maps.squeeze()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_dataio(model, data_loader, alphabet, last_n_layers=5, device=\"cuda\"):\n",
    "    model = model.to(device)\n",
    "    for batch in data_loader:\n",
    "        tokens, contacts = batch\n",
    "        tokens = tokens.to(device)\n",
    "        att_maps = get_att_map(tokens, model, alphabet, last_n_layers)\n",
    "        assert att_maps.shape[-2] == contacts.shape[-1], \"attention map length does not match contact map length\"\n",
    "        assert att_maps.shape[-3] == contacts.shape[-2], \"attention map length does not match contact map length\"\n",
    "        assert att_maps.shape[0] == contacts.shape[0], \"batch size does not match\"\n",
    "        break\n",
    "\n",
    "class Hparams():\n",
    "    def __init__(self):\n",
    "        self.max_len = 300\n",
    "        self.num_workers = 2\n",
    "        self.pin_memory = True\n",
    "        self.shuffle = True\n",
    "        self.name = \"esm1_t12_85M_UR50S\" # esm1_t12_85M_UR50S, esm1_t34_670M_UR50S\n",
    "        self.last_n_layers = 10\n",
    "        self.heads = 12 # for esm1_t12_85M_UR50S\n",
    "        self.head_dim = self.last_n_layers*self.heads\n",
    "        self.toks_per_batch = 1000\n",
    "        self.weight_term = 1\n",
    "        self.lr = 1e-3\n",
    "        self.wd = 1e-4\n",
    "        self.num_epochs = 5\n",
    "        self.classes = 2\n",
    "\n",
    "config = Hparams()\n",
    "model, alphabet, _, head = get_model(name=config.name)\n",
    "batch_converter = BatchConverterContact(alphabet, truncation_seq_length=config.max_len)\n",
    "dataset = DatasetAttMap(esm_structural_train, contact_maps=True, max_len=config.max_len)\n",
    "print(\"Used data:\", len(dataset), 'max len', config.max_len)\n",
    "print(f\" {config.name}, prepend_bos: {int(alphabet.prepend_bos)} append_eos:{int(alphabet.append_eos)}\")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "print(f\"Grouping by sequence length with maximum number of tokens per batch of {config.toks_per_batch}\")\n",
    "batches = DatasetAttMap.get_batch_indices(dataset, toks_per_batch=config.toks_per_batch)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, collate_fn=batch_converter, batch_sampler=batches)\n",
    "%timeit test_dataio(model, data_loader, alphabet,last_n_layers=config.last_n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the weighting term\n",
    "Contacts and non-contacts don't occur with the same frequency in the dataset.\n",
    "We can estimate the ratio of non-contacts to contacts in the dataset and use this to weight the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetAttMap(esm_structural_train, contact_maps=True, max_len=config.max_len)\n",
    "### START CODE HERE ### (≈ 5 lines of code)\n",
    "\n",
    "### END CODE HERE ###\n",
    "print(\"non-padded ratio\", ratio)\n",
    "config.weight_term = ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result:\n",
    "`17.36562728881836`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V. Train a linear layer to predict contact maps from ESM embeddings\n",
    "\n",
    "Complete the code to train a linear layer to predict contact maps from ESM embeddings. Since the contacts and non-contacts are imbalanced, we will not use accuracy as the metric. Instead, we will use the F1 score, which is defined as follows:\n",
    "$$\n",
    "F_1 = \\frac{2TP}{2TP + FP + FN}\n",
    "$$\n",
    "where $TP$ is the number of true positives (prediction is 1 and target is 1), $FP$ is the number of false positives (prediction is 1, but target is 0), and $FN$ is the number of false negatives (prediction is 0, but target is 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The head will be a linear layer with with input dim\", config.head_dim, \"and output dim\", config.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(tp, fp, fn):\n",
    "    return (2*tp)/(2*tp+fp+fn)\n",
    "\n",
    "def train_one_epoch(model, head, optimizer, train_loader, criterion, device, config):\n",
    "    model.train()\n",
    "    loss_step = []\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for batch in tqdm(train_loader, leave=False, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        ### START CODE HERE ### (≈ 10 lines of code)\n",
    "        # Do the forward and backward pass\n",
    "        # Track the loss in `loss_step`\n",
    "        # Track the number of true positives, false positives, and false negatives and add them to `tp`, `fp`, and `fn`\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "    loss_curr_epoch = np.mean(loss_step)\n",
    "    train_f1 = f1_score(tp, fp, fn).cpu().item()\n",
    "    return loss_curr_epoch, train_f1\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, head, val_loader, device, criterion):\n",
    "    model.eval()\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    loss_step = []\n",
    "    for batch in val_loader:\n",
    "        ### START CODE HERE ### (≈ 7 lines of code)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "    # don't forget to take the means here\n",
    "    val_f1 = f1_score(tp, fp, fn).cpu().item()\n",
    "    val_loss_epoch = torch.tensor(loss_step).mean().numpy()\n",
    "    return val_f1 , val_loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIVEN\n",
    "def train(model, head, optimizer, config, train_loader, val_loader, criterion, device):\n",
    "    best_val_loss = 1e8\n",
    "    best_val_f1 = 0\n",
    "    model = model.to(device)\n",
    "    dict_log = {\"train_f1_epoch\":[], \"val_f1_epoch\":[], \"loss_epoch\":[], \"val_loss\":[]}\n",
    "    with tqdm(range(config.num_epochs), desc=\"Epoch\") as pbar:\n",
    "        for epoch in pbar:\n",
    "            loss_curr_epoch, train_f1 = train_one_epoch(model, head, optimizer, train_loader, criterion, device, config)\n",
    "            val_f1, val_loss = validate(model, head, val_loader, device, criterion)\n",
    "\n",
    "            # Print epoch results to screen\n",
    "            msg = f'F1 : Train:{train_f1:.2f} \\t Val:{val_f1:.2f} || Loss: Train {loss_curr_epoch:.3f} \\t Val {val_loss:.3f}'\n",
    "            pbar.set_postfix_str(msg)\n",
    "            # Track stats\n",
    "            dict_log[\"train_f1_epoch\"].append(train_f1)\n",
    "            dict_log[\"val_f1_epoch\"].append(val_f1)\n",
    "            dict_log[\"loss_epoch\"].append(loss_curr_epoch)\n",
    "            dict_log[\"val_loss\"].append(val_loss)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save({\n",
    "                      'epoch': epoch,\n",
    "                      'model_state_dict': model.state_dict(),\n",
    "                      'optimizer_state_dict': optimizer.state_dict(),\n",
    "                      'loss': val_loss,\n",
    "                      }, f'best_model_min_val_loss.pth')\n",
    "\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                torch.save({\n",
    "                      'epoch': epoch,\n",
    "                      'model_state_dict': model.state_dict(),\n",
    "                      'optimizer_state_dict': optimizer.state_dict(),\n",
    "                      'loss': val_loss,\n",
    "                      }, f'best_model_max_val_f1.pth')\n",
    "    return dict_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(device=\"cuda\"):\n",
    "    dataset = DatasetAttMap(esm_structural_train, contact_maps=True, max_len=config.max_len)\n",
    "    val_dataset = DatasetAttMap(esm_structural_valid, contact_maps=True, max_len=config.max_len)\n",
    "    model, alphabet, _, _ = get_model(name=config.name)\n",
    "    head = torch.nn.Linear(config.head_dim, config.classes, bias=True)\n",
    "    batch_converter = BatchConverterContact(alphabet, truncation_seq_length=config.max_len)\n",
    "    batches = DatasetAttMap.get_batch_indices(dataset, toks_per_batch=config.toks_per_batch)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, collate_fn=batch_converter, batch_sampler=batches)\n",
    "    val_batches = DatasetAttMap.get_batch_indices(val_dataset, toks_per_batch=config.toks_per_batch)\n",
    "    val_data_loader = torch.utils.data.DataLoader(val_dataset, collate_fn=batch_converter, batch_sampler=val_batches)\n",
    "    model = model.to(device)\n",
    "    head = head.to(device)\n",
    "    optimizer = torch.optim.Adam(head.parameters(), lr=config.lr, weight_decay=config.wd)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([1, config.weight_term])).to(device)\n",
    "    return train(model, head, optimizer, config, data_loader, val_data_loader, criterion, device=device)\n",
    "\n",
    "dict_log = main(DEVICE)\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_stats(dict_log, modelname=config.name, title=f\"Contact Map Prediction {config.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected validation F1 score: ~0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "That's the end of this exercise. If you reached this point, **congratulations**!\n",
    "\n",
    "- Optional: Train with distograms instead of contact maps similar to [Verkuil, R., Kabeli, O., Du, Y., Wicky, B. I., Milles, L. F., Dauparas, J., ... & Rives, A. (2022). Language models generalize beyond natural proteins. bioRxiv, 2022-12.](https://www.biorxiv.org/content/10.1101/2022.12.21.521521v1.full.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc5fcf396fe0abd4fa852aee332a0572494dcaf5776820055c87d9b84157f362"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
